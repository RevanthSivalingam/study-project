# ============================================
# LLM Provider Configuration
# ============================================

# Which LLM provider to use: "openai", "gemini", or "none"
# Default: "none" (uses retrieval-only mode)
LLM_PROVIDER=none

# ============================================
# OpenAI Configuration
# ============================================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Model options: gpt-4-turbo-preview, gpt-3.5-turbo, gpt-4
OPENAI_MODEL=gpt-4-turbo-preview

# Maximum tokens in response (adjust based on your needs)
OPENAI_MAX_TOKENS=500

# Temperature: 0.0 (factual) to 1.0 (creative)
OPENAI_TEMPERATURE=0.3

# ============================================
# Google Gemini Configuration
# ============================================
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=

# Model options: gemini-1.5-pro, gemini-1.0-pro
GEMINI_MODEL=gemini-1.5-pro

# Maximum tokens in response
GEMINI_MAX_TOKENS=500

# Temperature: 0.0 (factual) to 1.0 (creative)
GEMINI_TEMPERATURE=0.3

# ============================================
# System Behavior
# ============================================
# Fall back to MMR if LLM fails (true/false)
FALLBACK_TO_MMR=true
